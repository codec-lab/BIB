{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from tqdm import tqdm\n",
    "\n",
    "#custom file\n",
    "from scratch_data import *\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a general Pipeline of how surprise scores are generated as they are in the paper. <br>\n",
    "The pipeline covers:\n",
    "- Reading in training data, and test-expected data and test-unexpected data. (All normal train data is expected)\n",
    "- Using a simple CNN model to do behavioral cloning (predicting actions just given states -- not state, prev_actions)\n",
    "- Calculating Surprise Scores\n",
    "<br>\n",
    "This code used a lot of the existing code from the og BiB repo. However some things have been changed, and the class structure of how things were processed in the original \n",
    "repo has been disassembled to run each function discretely to make it clear how the operation worked. All code used from the scratch_data file is understood well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading files of type preference\n"
     ]
    }
   ],
   "source": [
    "type = 'preference'\n",
    "path = r'/home/mike/Desktop/Codec_research/bib_evaluation_v1.1/bib_evaluation/'\n",
    "expected_data_tuples, unexpected_data_tuples = get_data_tuples(path,type,False) #mp4 path, frame number, action (-1 to 1)\n",
    "#False because the data was processed already (huge time save)\n",
    "total_episodes = len(expected_data_tuples)/9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading files of type preference\n"
     ]
    }
   ],
   "source": [
    "train_path = r'/home/mike/Desktop/Codec_research/bib_train'\n",
    "train_tuples = get_train_tuples(train_path,type,False)\n",
    "train_episodes = len(train_tuples)/9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000 9000\n"
     ]
    }
   ],
   "source": [
    "print(len(expected_data_tuples), len(unexpected_data_tuples)) #total eval frames\n",
    "print(f'Total Evaluation Episodes: {total_episodes}')\n",
    "print(f'Total Training Episodes: {train_episodes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_results = []\n",
    "# for i in range(int(total_episodes)):\n",
    "#     trial_indices = get_episode_trial_indices(episode_index=i)\n",
    "#     trial_result = get_trial(data_tuples, trial_indices, num_transitions=30,action_range = 10, step=1)\n",
    "#     train_results.append(trial_result)\n",
    "#Causes crash because to much memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From here,\n",
    "#Loop through a bunch of episodes \n",
    "#Get train data, val, test\n",
    "#Use a simple CNN model to predict actions?\n",
    "#Compare with prev one that used the prev action in the prediction -- or did it? (Doble check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if gpu is being used\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictive Engine here: \n",
    "#One they use is more involved and also includes actions in the prediction\n",
    "#Paper encodes states first and concatinate with actions\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        \n",
    "        self.fc1 = nn.Linear(64 * 10 * 10, 128)  # After pooling, the feature map size is 10x10\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        \n",
    "        x = x.view(-1, 64 * 10 * 10)  # Flatten the feature map\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        x = torch.tanh(x)  # Ensure output is between -1 and 1 for predicting actions\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_result = get_trial(train_tuples, get_episode_trial_indices(episode_index=0), num_transitions=30,action_range = 10, step=1)[1]\n",
    "#trial_result to play and see what a trial looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleCNN()\n",
    "\n",
    "#loss function\n",
    "criterion = nn.MSELoss()\n",
    "#optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "#train the model\n",
    "def train(model, data,criterion, optimizer,epochs):\n",
    "    train_length = int(len(data)/9) #9 trials per episode\n",
    "    for epoch in range(epochs):\n",
    "        random_order = random.sample(list(range(train_length)), train_length)\n",
    "        for i in random_order: #processes loss 1 episode at a time, doing loss in random order\n",
    "            #get data\n",
    "            trial_indices = get_episode_trial_indices(episode_index=i)\n",
    "            trial_result = get_trial(data, trial_indices, num_transitions=30,action_range = 10, step=1)\n",
    "            states = trial_result[0]\n",
    "            actions = trial_result[1]\n",
    "            #convert to tensor\n",
    "            states = torch.tensor(states).float()\n",
    "            actions = torch.tensor(actions).float()\n",
    "            #forward pass\n",
    "            outputs = model(states)\n",
    "            loss = criterion(outputs, actions)\n",
    "            #backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f'Epoch {epoch+1}, Loss: {loss.item()}')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_207812/2890571682.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  states = torch.tensor(states).float()\n",
      "/tmp/ipykernel_207812/2890571682.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  actions = torch.tensor(actions).float()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.3422279357910156\n",
      "Epoch 2, Loss: 0.3297484815120697\n",
      "Epoch 3, Loss: 0.3267993628978729\n"
     ]
    }
   ],
   "source": [
    "#train(model, train_tuples,criterion, optimizer, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "#torch.save(model.state_dict(), 'simple_cnn.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model\n",
    "model = SimpleCNN()\n",
    "model.load_state_dict(torch.load('simple_cnn.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test model\n",
    "def get_surprise_score(model, data):\n",
    "    surprise_scores = []\n",
    "    for i in range(int(len(data)/9)):\n",
    "        trial_indices = get_episode_trial_indices(episode_index=i)\n",
    "        trial_result = get_trial(data, trial_indices, num_transitions=30,action_range = 10, step=1)\n",
    "        states = trial_result[0]\n",
    "        actions = trial_result[1]\n",
    "        states = torch.tensor(states).float()\n",
    "        actions = torch.tensor(actions).float()\n",
    "        outputs = model(states)\n",
    "        surprise_score = criterion(outputs, actions).item()\n",
    "        surprise_scores.append(surprise_score)\n",
    "    max_surprise_score = max(surprise_scores)\n",
    "    mean_surprise_score = np.mean(surprise_scores)\n",
    "    return max_surprise_score, mean_surprise_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_207812/886555001.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  states = torch.tensor(states).float()\n",
      "/tmp/ipykernel_207812/886555001.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  actions = torch.tensor(actions).float()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5188149809837341, 0.3084702689496961)\n",
      "(0.8545089960098267, 0.5518209140896797)\n",
      "(0.880501925945282, 0.5486014810800552)\n"
     ]
    }
   ],
   "source": [
    "print(get_surprise_score(model, train_tuples))\n",
    "print(get_surprise_score(model, expected_data_tuples))\n",
    "print(get_surprise_score(model, unexpected_data_tuples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
