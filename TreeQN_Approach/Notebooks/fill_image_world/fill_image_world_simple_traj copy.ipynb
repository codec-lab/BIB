{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.nn import Parameter\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.optim import RMSprop\n",
    "\n",
    "from treeQN.treeqn_traj_simple_nl import TreeQN\n",
    "import random\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 16])\n",
      "torch.Size([16, 1, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create the tensor\n",
    "tensor = torch.ones(16,1, 4, 4)\n",
    "\n",
    "# Flatten dimensions 1 and 2\n",
    "\n",
    "#reverse process\n",
    "\n",
    "def flattener(tensor):\n",
    "    return torch.flatten(tensor, start_dim=2, end_dim=3).squeeze(1)\n",
    "def unflattener(tensor):\n",
    "    return tensor.view(-1, 1, 4, 4)\n",
    "\n",
    "flat = flattener(tensor)\n",
    "print(flat.shape)  # Output: torch.Size([4, 16])\n",
    "unflat = unflattener(flat)\n",
    "print(unflat.shape)  # Output: torch.Size([4, 1, 4, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_world(tensor,max_val): \n",
    "    assert tensor.shape[0] == tensor.shape[1]\n",
    "    val = tensor.max() + 1\n",
    "    state = torch.zeros_like(tensor).unsqueeze(0).unsqueeze(0) #to match treeqn input size\n",
    "    new_state = torch.ones_like(state)\n",
    "    middle = int(tensor.shape[0] / 2)\n",
    "    # Create transitions by modifying slices of new_state\n",
    "    new_state[:,:,:middle, :middle] += val\n",
    "    transition_one = new_state.clone()\n",
    "    new_state[:,:,middle:, :middle] += val\n",
    "    transition_two = new_state.clone()\n",
    "    new_state[:,:,:middle, middle:] += val\n",
    "    transition_three = new_state.clone()\n",
    "    new_state[:,:,middle:, middle:] += val #transition 4\n",
    "    return [transition_one/max_val, transition_two/max_val, transition_three/max_val, new_state/max_val]\n",
    "def image_world_samples(size_tensor,samples,max_val=1,x_input=-1):\n",
    "    return_data = []\n",
    "    for i in range(samples):\n",
    "        loc_tensor = torch.zeros_like(size_tensor)+0.1\n",
    "        x = int(random.random()*size_tensor.shape[0])\n",
    "        if x_input != -1:\n",
    "            x = x_input\n",
    "        loc_tensor[x] += x\n",
    "        result = image_world(loc_tensor,max_val)\n",
    "        loc_tensor = loc_tensor.unsqueeze(0).unsqueeze(0)/max_val\n",
    "        return_data.append([loc_tensor,result])\n",
    "    return return_data\n",
    "\n",
    "size_tensor = torch.zeros(20,20)\n",
    "train_data = image_world_samples(size_tensor,1000,size_tensor.shape[0],-1)\n",
    "\n",
    "test_data = [] #simply test once on all 20 possible initial states.\n",
    "for i in range(size_tensor.shape[0]):\n",
    "    test_data.append(image_world_samples(size_tensor,1,size_tensor.shape[0],i)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mike/Desktop/TreeQN/BIB/TreeQN_Approach/treeQN/treeqn_traj_simple_nl.py:33: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  b_init(module.bias, b_scale)\n"
     ]
    }
   ],
   "source": [
    "input_shape = torch.zeros(1, 1,20, 20).shape# minimum size #train_data[0][0].shape\n",
    "num_actions = 4\n",
    "tree_depth = 4\n",
    "embedding_dim = 400\n",
    "td_lambda = 0.8\n",
    "gamma = 1    #0.99\n",
    "model = TreeQN(input_shape=input_shape, num_actions=num_actions, tree_depth=tree_depth, embedding_dim=embedding_dim, td_lambda=td_lambda,gamma=gamma)\n",
    "optimizer = Adam(model.parameters(), lr=1e-2)\n",
    "#optimizer = RMSprop(model.parameters(), lr=1e-4,alpha =0.99, eps = 1e-5) | loss from treeqn paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_316867/823553769.py:33: UserWarning: Using a target size (torch.Size([1, 1, 20, 20])) that is different to the input size (torch.Size([4, 1, 20, 20])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  first_loss = (F.mse_loss(decoded_values[1], t[1][0], reduction='none') * first).sum()\n",
      "/tmp/ipykernel_316867/823553769.py:34: UserWarning: Using a target size (torch.Size([1, 1, 20, 20])) that is different to the input size (torch.Size([16, 1, 20, 20])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  second_loss = (F.mse_loss(decoded_values[2], t[1][1], reduction='none') * second).sum()\n",
      "/tmp/ipykernel_316867/823553769.py:35: UserWarning: Using a target size (torch.Size([1, 1, 20, 20])) that is different to the input size (torch.Size([64, 1, 20, 20])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  third_loss = (F.mse_loss(decoded_values[3], t[1][2], reduction='none') * third).sum()\n",
      "/tmp/ipykernel_316867/823553769.py:36: UserWarning: Using a target size (torch.Size([1, 1, 20, 20])) that is different to the input size (torch.Size([256, 1, 20, 20])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  fourth_loss = (F.mse_loss(decoded_values[4], t[1][3], reduction='none') * fourth).sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Average Loss: 401.6286220498085, Average Raw Loss: 401.6286220498085\n",
      "Epoch 2, Average Loss: 401.39008999156954, Average Raw Loss: 401.39008999156954\n",
      "Epoch 3, Average Loss: 393.8816440272331, Average Raw Loss: 393.8816440272331\n",
      "Epoch 4, Average Loss: 352.0204865489006, Average Raw Loss: 352.0204865489006\n",
      "Epoch 5, Average Loss: 298.2004686017036, Average Raw Loss: 298.2004686017036\n",
      "Epoch 6, Average Loss: 250.05965869235993, Average Raw Loss: 250.05965869235993\n",
      "Epoch 7, Average Loss: 213.75368000030517, Average Raw Loss: 213.75368000030517\n",
      "Epoch 8, Average Loss: 187.59350961208344, Average Raw Loss: 187.59350961208344\n",
      "Epoch 9, Average Loss: 168.770596367836, Average Raw Loss: 168.770596367836\n",
      "Epoch 10, Average Loss: 154.3704054918289, Average Raw Loss: 154.3704054918289\n",
      "Epoch 11, Average Loss: 144.16860142993926, Average Raw Loss: 144.16860142993926\n",
      "Epoch 12, Average Loss: 137.30780815410614, Average Raw Loss: 137.30780815410614\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 51\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_count \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     50\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 51\u001b[0m     \u001b[43mtemp_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;66;03m#torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\u001b[39;00m\n\u001b[1;32m     54\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Main training loop\n",
    "#Looking at difference between detaching at each transition or not in treeqn file. This is with detach (so far seems to make no diff)\n",
    "raw_losses = []\n",
    "for epoch in range(3000):  # epochs\n",
    "    avg_loss = 0\n",
    "    temp_loss = 0\n",
    "    temp_raw_loss = 0\n",
    "    sample_count = 0\n",
    "\n",
    "    avg_raw_loss = 0\n",
    "\n",
    "    for t in random.sample(train_data, len(train_data)): #sample through all data in random order each epoch\n",
    "        #Get reconstruction loss to help ground abstract state\n",
    "        decoded_values, all_policies = model(t[0])\n",
    "\n",
    "        #Get transition probabilities for each state\n",
    "        first_policy = all_policies[0]\n",
    "        second_policy = all_policies[1].view(4, -1)\n",
    "        third_policy = all_policies[2].view(4, 4, -1)\n",
    "        fourth_policy = all_policies[3].view(4, 4, 4, -1)\n",
    "\n",
    "        #These should all add to 1 (in testing there seems to be some small rounding error)\n",
    "        second_layer_probs = first_policy * second_policy   \n",
    "        third_layer_probs = second_layer_probs * third_policy\n",
    "        fourth_layer_probs = third_layer_probs * fourth_policy\n",
    "        \n",
    "        #Flatten transition probabilities to then weigh with loss of each predicted state at each layer\n",
    "        first = torch.flatten(first_policy).view(4, 1, 1, 1)\n",
    "        second = torch.flatten(second_layer_probs).view(16, 1, 1, 1)\n",
    "        third = torch.flatten(third_layer_probs).view(64, 1, 1, 1)\n",
    "        fourth = torch.flatten(fourth_layer_probs).view(256, 1, 1, 1) \n",
    "        \n",
    "        first_loss = (F.mse_loss(decoded_values[1], t[1][0], reduction='none') * first).sum() \n",
    "        second_loss = (F.mse_loss(decoded_values[2], t[1][1], reduction='none') * second).sum() \n",
    "        third_loss = (F.mse_loss(decoded_values[3], t[1][2], reduction='none') * third).sum() \n",
    "        fourth_loss = (F.mse_loss(decoded_values[4], t[1][3], reduction='none') * fourth).sum() \n",
    "\n",
    "\n",
    "        #For experimenting with different weights on different layers\n",
    "        raw_loss = (first_loss + second_loss + third_loss + fourth_loss).detach().item()\n",
    "        raw_losses.append(raw_loss)\n",
    "        l2w , l3w ,l4w = 1,1,1\n",
    "        total_loss = first_loss + second_loss*l2w + third_loss*l3w + fourth_loss*l4w\n",
    "\n",
    "        temp_loss += total_loss\n",
    "        temp_raw_loss += raw_loss\n",
    "        sample_count += 1\n",
    "\n",
    "        if sample_count % 1 == 0:\n",
    "            optimizer.zero_grad()\n",
    "            temp_loss.backward()\n",
    "\n",
    "            #torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "            optimizer.step()\n",
    "            avg_loss += temp_loss.item()\n",
    "            avg_raw_loss += temp_raw_loss\n",
    "            temp_loss = 0\n",
    "            temp_raw_loss = 0\n",
    "\n",
    "    # To handle the case where the number of samples is not a multiple of 10\n",
    "    if sample_count % 1 != 0:\n",
    "        optimizer.zero_grad()\n",
    "        temp_loss.backward()\n",
    "        \n",
    "        #torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "        optimizer.step()\n",
    "        avg_loss += temp_loss.item()\n",
    "        avg_raw_loss += temp_raw_loss\n",
    "\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Average Loss: {avg_loss / len(train_data)}, Average Raw Loss: {avg_raw_loss / len(train_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action Weight Sums tensor([19.1120,  6.4280, -3.5560,  9.7770])\n"
     ]
    }
   ],
   "source": [
    "#View Action Weights (This hasn't been informative yet)\n",
    "dec, all_policies = model(train_data[0][0]) \n",
    "# dot = make_dot((dec[0],dec[1],dec[2],dec[3],dec[4],all_policies[0],all_policies[1],all_policies[2],all_policies[3]),params=dict(model.named_parameters()))\n",
    "# dot.render('model', format='png')\n",
    "print(f\"Action Weight Sums { torch.round(model.transition_fun.data,decimals=3).sum(dim=0).sum(dim=0)}\")  #might be summing the wrong way, or just not interesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Actions: 1 0 3 3\n"
     ]
    }
   ],
   "source": [
    "best_first_action = all_policies[0].argmax()\n",
    "best_second_action = all_policies[1].view(4,-1)[best_first_action].argmax() \n",
    "best_third_action = all_policies[2].view(4,4,-1)[best_first_action][best_second_action].argmax()\n",
    "best_fourth_action = all_policies[3].view(4,4,4,-1)[best_first_action][best_second_action][best_third_action].argmax() \n",
    "# print(torch.round(all_q[0],decimals=3).detach(), f\"Argmax {all_q[0].argmax().item()}\")\n",
    "# print(torch.round(all_q[1],decimals=3).view(4,-1).detach(),f\"Argmax {all_q[1].view(4,-1)[1].argmax().item()}\")\n",
    "# print(torch.round(all_q[2],decimals=3).view(4,4,-1)[0].detach(),f\"Argmax {all_q[2].view(4,4,-1)[1][0].argmax().item()}\")\n",
    "# print(torch.round(all_q[3],decimals=3).view(4,4,4,-1)[0][0].detach(),f\"Argmax {all_q[3].view(4,4,4,-1)[1][1][0].argmax().item()}\")\n",
    "print(f\"Best Actions: {best_first_action.item()} {best_second_action.item()} {best_third_action.item()} {best_fourth_action.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_316221/1188555054.py:27: UserWarning: Using a target size (torch.Size([1, 1, 20, 20])) that is different to the input size (torch.Size([4, 1, 20, 20])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  first_loss = (F.mse_loss(decoded_values[1], t[1][0], reduction='none') * first).sum()\n",
      "/tmp/ipykernel_316221/1188555054.py:28: UserWarning: Using a target size (torch.Size([1, 1, 20, 20])) that is different to the input size (torch.Size([16, 1, 20, 20])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  second_loss = (F.mse_loss(decoded_values[2], t[1][1], reduction='none') * second).sum()\n",
      "/tmp/ipykernel_316221/1188555054.py:29: UserWarning: Using a target size (torch.Size([1, 1, 20, 20])) that is different to the input size (torch.Size([64, 1, 20, 20])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  third_loss = (F.mse_loss(decoded_values[3], t[1][2], reduction='none') * third).sum()\n",
      "/tmp/ipykernel_316221/1188555054.py:30: UserWarning: Using a target size (torch.Size([1, 1, 20, 20])) that is different to the input size (torch.Size([256, 1, 20, 20])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  fourth_loss = (F.mse_loss(decoded_values[4], t[1][3], reduction='none') * fourth).sum()\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "loss_data = []\n",
    "with torch.no_grad():\n",
    "    eval_loss = 0\n",
    "    for i,k in zip(test_data,range(len(test_data))):\n",
    "        #Get reconstruction loss to help ground abstract state\n",
    "        decoded_values, all_policies = model(t[0])\n",
    "        decode_loss = F.mse_loss(decoded_values[0], t[0], reduction='sum')\n",
    "\n",
    "        #Get transition probabilities for each state\n",
    "        first_policy = all_policies[0]\n",
    "        second_policy = all_policies[1].view(4, -1)\n",
    "        third_policy = all_policies[2].view(4, 4, -1)\n",
    "        fourth_policy = all_policies[3].view(4, 4, 4, -1)\n",
    "\n",
    "        #These should all add to 1 (in testing there seems to be some small rounding error)\n",
    "        second_layer_probs = first_policy * second_policy   \n",
    "        third_layer_probs = second_layer_probs * third_policy\n",
    "        fourth_layer_probs = third_layer_probs * fourth_policy\n",
    "        \n",
    "        #Flatten transition probabilities to then weigh with loss of each predicted state at each layer\n",
    "        first = torch.flatten(first_policy).view(4, 1, 1, 1)\n",
    "        second = torch.flatten(second_layer_probs).view(16, 1, 1, 1)\n",
    "        third = torch.flatten(third_layer_probs).view(64, 1, 1, 1)\n",
    "        fourth = torch.flatten(fourth_layer_probs).view(256, 1, 1, 1) \n",
    "        \n",
    "        first_loss = (F.mse_loss(decoded_values[1], t[1][0], reduction='none') * first).sum() \n",
    "        second_loss = (F.mse_loss(decoded_values[2], t[1][1], reduction='none') * second).sum() \n",
    "        third_loss = (F.mse_loss(decoded_values[3], t[1][2], reduction='none') * third).sum() \n",
    "        fourth_loss = (F.mse_loss(decoded_values[4], t[1][3], reduction='none') * fourth).sum() \n",
    "\n",
    "        #For experimenting with different weights on different layers\n",
    "        raw_loss = (decode_loss + first_loss + second_loss + third_loss + fourth_loss).detach().item()\n",
    "\n",
    "        loss_data.append([k,decode_loss.item(),first_loss.item(),second_loss.item(),third_loss.item(),fourth_loss.item(),raw_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Decode Loss</th>\n",
       "      <th>First Loss</th>\n",
       "      <th>Second Loss</th>\n",
       "      <th>Third Loss</th>\n",
       "      <th>Fourth Loss</th>\n",
       "      <th>Total Loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Starting Input</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.64</td>\n",
       "      <td>66.14</td>\n",
       "      <td>128.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>199.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.64</td>\n",
       "      <td>66.14</td>\n",
       "      <td>128.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>199.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.64</td>\n",
       "      <td>66.14</td>\n",
       "      <td>128.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>199.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.64</td>\n",
       "      <td>66.14</td>\n",
       "      <td>128.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>199.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.64</td>\n",
       "      <td>66.14</td>\n",
       "      <td>128.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>199.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.64</td>\n",
       "      <td>66.14</td>\n",
       "      <td>128.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>199.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.64</td>\n",
       "      <td>66.14</td>\n",
       "      <td>128.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>199.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.64</td>\n",
       "      <td>66.14</td>\n",
       "      <td>128.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>199.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.64</td>\n",
       "      <td>66.14</td>\n",
       "      <td>128.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>199.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.64</td>\n",
       "      <td>66.14</td>\n",
       "      <td>128.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>199.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.64</td>\n",
       "      <td>66.14</td>\n",
       "      <td>128.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>199.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.64</td>\n",
       "      <td>66.14</td>\n",
       "      <td>128.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>199.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.64</td>\n",
       "      <td>66.14</td>\n",
       "      <td>128.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>199.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.64</td>\n",
       "      <td>66.14</td>\n",
       "      <td>128.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>199.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.64</td>\n",
       "      <td>66.14</td>\n",
       "      <td>128.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>199.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.64</td>\n",
       "      <td>66.14</td>\n",
       "      <td>128.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>199.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.64</td>\n",
       "      <td>66.14</td>\n",
       "      <td>128.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>199.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.64</td>\n",
       "      <td>66.14</td>\n",
       "      <td>128.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>199.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4.64</td>\n",
       "      <td>66.14</td>\n",
       "      <td>128.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>199.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4.64</td>\n",
       "      <td>66.14</td>\n",
       "      <td>128.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>199.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Decode Loss  First Loss  Second Loss  Third Loss  Fourth Loss  \\\n",
       "Starting Input                                                                  \n",
       "0                      4.64       66.14       128.43         0.0          0.0   \n",
       "1                      4.64       66.14       128.43         0.0          0.0   \n",
       "2                      4.64       66.14       128.43         0.0          0.0   \n",
       "3                      4.64       66.14       128.43         0.0          0.0   \n",
       "4                      4.64       66.14       128.43         0.0          0.0   \n",
       "5                      4.64       66.14       128.43         0.0          0.0   \n",
       "6                      4.64       66.14       128.43         0.0          0.0   \n",
       "7                      4.64       66.14       128.43         0.0          0.0   \n",
       "8                      4.64       66.14       128.43         0.0          0.0   \n",
       "9                      4.64       66.14       128.43         0.0          0.0   \n",
       "10                     4.64       66.14       128.43         0.0          0.0   \n",
       "11                     4.64       66.14       128.43         0.0          0.0   \n",
       "12                     4.64       66.14       128.43         0.0          0.0   \n",
       "13                     4.64       66.14       128.43         0.0          0.0   \n",
       "14                     4.64       66.14       128.43         0.0          0.0   \n",
       "15                     4.64       66.14       128.43         0.0          0.0   \n",
       "16                     4.64       66.14       128.43         0.0          0.0   \n",
       "17                     4.64       66.14       128.43         0.0          0.0   \n",
       "18                     4.64       66.14       128.43         0.0          0.0   \n",
       "19                     4.64       66.14       128.43         0.0          0.0   \n",
       "\n",
       "                Total Loss  \n",
       "Starting Input              \n",
       "0                   199.22  \n",
       "1                   199.22  \n",
       "2                   199.22  \n",
       "3                   199.22  \n",
       "4                   199.22  \n",
       "5                   199.22  \n",
       "6                   199.22  \n",
       "7                   199.22  \n",
       "8                   199.22  \n",
       "9                   199.22  \n",
       "10                  199.22  \n",
       "11                  199.22  \n",
       "12                  199.22  \n",
       "13                  199.22  \n",
       "14                  199.22  \n",
       "15                  199.22  \n",
       "16                  199.22  \n",
       "17                  199.22  \n",
       "18                  199.22  \n",
       "19                  199.22  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_df = pd.DataFrame(loss_data,columns=[\"Starting Input\",\"Decode Loss\",\"First Loss\",\"Second Loss\",\"Third Loss\",\"Fourth Loss\",\"Total Loss\"]).set_index(\"Starting Input\").round(2)\n",
    "loss_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([106.39837646484375,\n",
       "  188.68629455566406,\n",
       "  273.97283935546875,\n",
       "  357.491943359375],\n",
       " [107.59789276123047, 190.6305389404297, 276.2881164550781, 360.773681640625])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#A check on if the training loop is valid\n",
    "#Checking loss of each state unweighted, with both absolute difference loss and mse loss\n",
    "#The earlier transitoins might be easier since it's easier to learn that a lot the environment is the same\n",
    "min_losses = []\n",
    "max_losses = []\n",
    "for i in range(1,len(dec)):\n",
    "    decoded_states = dec[i]\n",
    "    true_state = train_data[0][1][i-1]\n",
    "    curr_min = float('inf')\n",
    "    curr_max = float('-inf')\n",
    "    for state in decoded_states:\n",
    "        loss = torch.abs(state-true_state).sum()\n",
    "        if loss < curr_min:\n",
    "            curr_min = loss.item()\n",
    "        if loss > curr_max:\n",
    "            curr_max = loss.item()\n",
    "    min_losses.append(curr_min)\n",
    "    max_losses.append(curr_max)\n",
    "min_losses,max_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_316221/3588761361.py:9: UserWarning: Using a target size (torch.Size([1, 1, 20, 20])) that is different to the input size (torch.Size([1, 20, 20])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(state,true_state)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.20626585185527802,\n",
       "  0.40149348974227905,\n",
       "  0.6037805676460266,\n",
       "  0.8011261820793152],\n",
       " [0.20811262726783752,\n",
       "  0.40544643998146057,\n",
       "  0.6117904186248779,\n",
       "  0.8159759640693665])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_losses = []\n",
    "max_losses = []\n",
    "for i in range(1,len(dec)):\n",
    "    decoded_states = dec[i]\n",
    "    true_state = train_data[0][1][i-1]\n",
    "    curr_min = float('inf')\n",
    "    curr_max = float('-inf')\n",
    "    for state in decoded_states:\n",
    "        loss = F.mse_loss(state,true_state)\n",
    "        if loss < curr_min:\n",
    "            curr_min = loss.item()\n",
    "        if loss > curr_max:\n",
    "            curr_max = loss.item()\n",
    "    min_losses.append(curr_min)\n",
    "    max_losses.append(curr_max)\n",
    "min_losses,max_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
