{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.nn import Parameter\n",
    "\n",
    "from torch.optim import Adam\n",
    "\n",
    "from treeqn_traj_simplest import TreeQN\n",
    "import image_world\n",
    "import random\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data = image_world.get_data(size = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0025)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.zeros(20,20)\n",
    "b = torch.zeros(20,20)\n",
    "b[0][0] = 1\n",
    "F.mse_loss(a,b) #Target Loss should be at least less than this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Addition Transition\n"
     ]
    }
   ],
   "source": [
    "input_shape = train_data[0][0].shape# minimum size #train_data[0][0].shape\n",
    "num_actions = 4\n",
    "tree_depth = 4\n",
    "embedding_dim = 64\n",
    "gamma = 1 \n",
    "decode_dropout = 0.5\n",
    "t1 =False#True is Einsum. False +dx \n",
    "model = TreeQN(input_shape=input_shape, num_actions=num_actions, tree_depth=tree_depth, embedding_dim=embedding_dim, gamma=gamma,decode_dropout=decode_dropout,t1=t1)\n",
    "optimizer = Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Optional: Pretrain Autoencoder</h1>\n",
    "(Doesn't seem necessary, useful for testing if decoding Z is possible though)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_world.train_autoencoder(model,optimizer,train_data,valid_data,epochs=100,lambda_reg=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #freeze encoder and decoder\n",
    "# for param in model.encoder.parameters():\n",
    "#     param.requires_grad = False\n",
    "# for param in model.decoder.parameters():\n",
    "#     param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #test_autoencode ability\n",
    "# def test_autoencoder(model,valid_data):\n",
    "#     with torch.no_grad():\n",
    "#         test_sample = random.choice(valid_data)\n",
    "#         encoding = model.encoder(test_sample[0])\n",
    "#         decoding = model.decoder(encoding)\n",
    "#         print('Original:\\n', test_sample[0].numpy()[0][0][4:-4, 4:-4])\n",
    "#         print('Reconstructed:\\n', np.round(decoding.numpy()[0][0][4:-4, 4:-4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Train Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mikef\\Desktop\\TreeQN_Github\\BIB\\TreeQN_Approach\\Notebooks\\image_gridworld\\image_world.py:129: UserWarning: Using a target size (torch.Size([1, 1, 20, 20])) that is different to the input size (torch.Size([4, 1, 20, 20])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  first_loss = (F.mse_loss(decoded_values[1], t[1], reduction='none') * first).sum().item()\n",
      "c:\\Users\\mikef\\Desktop\\TreeQN_Github\\BIB\\TreeQN_Approach\\Notebooks\\image_gridworld\\image_world.py:130: UserWarning: Using a target size (torch.Size([1, 1, 20, 20])) that is different to the input size (torch.Size([16, 1, 20, 20])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  second_loss = (F.mse_loss(decoded_values[2], t[2], reduction='none') * second).sum().item()\n",
      "c:\\Users\\mikef\\Desktop\\TreeQN_Github\\BIB\\TreeQN_Approach\\Notebooks\\image_gridworld\\image_world.py:131: UserWarning: Using a target size (torch.Size([1, 1, 20, 20])) that is different to the input size (torch.Size([64, 1, 20, 20])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  third_loss = (F.mse_loss(decoded_values[3], t[3], reduction='none') * third).sum().item()\n",
      "c:\\Users\\mikef\\Desktop\\TreeQN_Github\\BIB\\TreeQN_Approach\\Notebooks\\image_gridworld\\image_world.py:132: UserWarning: Using a target size (torch.Size([1, 1, 20, 20])) that is different to the input size (torch.Size([256, 1, 20, 20])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  fourth_loss = (F.mse_loss(decoded_values[4], t[4], reduction='none') * fourth).sum().item()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Validation Loss Weighted: 7.4315505027771, | Validation Unweighted Avg: 0.19917109608650208\n",
      "Epoch 1, Total Loss: 1.2242632088336078, DLoss: 1.2075781120495364, A1: 0.0037088934363881973, A2: 0.004093928370540115, A3: 0.0043763829797337, A4: 0.00450589331925254\n",
      "Epoch 2, Total Loss: 0.7962757179682906, DLoss: 0.7811783217570999, A1: 0.003111842741385441, A2: 0.003644602153111588, A3: 0.004061055342158811, A4: 0.004279895141636106\n",
      "Epoch 3, Total Loss: 0.2777337351136587, DLoss: 0.2618944889527153, A1: 0.0034190229944546114, A2: 0.003819341579748487, A3: 0.004188875748183239, A4: 0.004412004679695449\n",
      "Epoch 4, Total Loss: 0.05249040217392824, DLoss: 0.03674559223846617, A1: 0.003481004252733493, A2: 0.003763037458570166, A3: 0.004125462237491526, A4: 0.004375305977141993\n",
      "Epoch 5, Total Loss: 0.023803234650668772, DLoss: 0.008460839130566455, A1: 0.003413925662806088, A2: 0.003647099786692045, A3: 0.004003371396737004, A4: 0.004277998592111875\n",
      "Epoch 6, Total Loss: 0.03148675111376426, DLoss: 0.016439928947312926, A1: 0.003377901873847639, A2: 0.0035650702119296926, A3: 0.00391138000942936, A4: 0.004192469928371296\n",
      "Epoch 7, Total Loss: 0.016360022682188585, DLoss: 0.0016735544879338704, A1: 0.0033437436795793474, A2: 0.00345719917783175, A3: 0.0038004024292935023, A4: 0.0040851229304363105\n",
      "Epoch 8, Total Loss: 0.014962198966267434, DLoss: 0.0007383284842944704, A1: 0.0032897408575412223, A2: 0.003332086962605403, A3: 0.0036538877609101207, A4: 0.003948154874061319\n",
      "Epoch 9, Total Loss: 0.019544049191542647, DLoss: 0.005791090113052633, A1: 0.0032304754734716634, A2: 0.0032152361966754227, A3: 0.0035032221539454027, A4: 0.00380402527728372\n",
      "Epoch 10, Total Loss: 0.05183710057119077, DLoss: 0.0380200128917667, A1: 0.0032779845610176298, A2: 0.0032529142600568857, A3: 0.0035150258262133735, A4: 0.0037711629453538492\n",
      "Epoch 11, Validation Loss Weighted: 5.29200553894043, | Validation Unweighted Avg: 0.0031459517776966095\n",
      "Epoch 11, Total Loss: 0.02331594270654023, DLoss: 0.00976029299173123, A1: 0.003243526768743653, A2: 0.0031998437734066763, A3: 0.003435272986958311, A4: 0.003677006148394536\n",
      "Epoch 12, Total Loss: 0.014471541662615809, DLoss: 0.0014173281005324416, A1: 0.003176611428022046, A2: 0.0030948640397665175, A3: 0.0032787396149201826, A4: 0.0035039985182017765\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17452/2289588912.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# sample through all data in random order each epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;31m# Get reconstruction loss to help ground abstract state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mdecoded_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransition_probabilities\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mdecode_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecoded_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sum'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mikef\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[misc]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1517\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1518\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1520\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mikef\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1525\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1529\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mikef\\Desktop\\TreeQN_Github\\BIB\\TreeQN_Approach\\Notebooks\\image_gridworld\\treeqn_traj_simplest.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    305\u001b[0m         \u001b[0mdecoded_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0membedding\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtree_result\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'embeddings'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m             \u001b[0mdecoded_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdecoded_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransition_probs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mikef\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[misc]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1517\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1518\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1520\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mikef\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1525\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1529\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mikef\\Desktop\\TreeQN_Github\\BIB\\TreeQN_Approach\\Notebooks\\image_gridworld\\treeqn_traj_simplest.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[1;31m# Upsample through deconvolution layers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Output: (batch_size, 64, 10, 10)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Output: (batch_size, 32, 20, 20)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[1;31m# Final convolution to get the desired output size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mikef\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[misc]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1517\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1518\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1520\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mikef\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1525\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1529\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mikef\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, output_size)\u001b[0m\n\u001b[0;32m    950\u001b[0m             num_spatial_dims, self.dilation)  # type: ignore[arg-type]\n\u001b[0;32m    951\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 952\u001b[1;33m         return F.conv_transpose2d(\n\u001b[0m\u001b[0;32m    953\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m             output_padding, self.groups, self.dilation)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_gradients = []\n",
    "model.train()  \n",
    "\n",
    "for epoch in range(3000):  # epochs\n",
    "    avg_loss = 0\n",
    "    avg_decode_loss, avg_first_loss, avg_second_loss, avg_third_loss, avg_fourth_loss = 0, 0, 0, 0, 0\n",
    "    raw_gradients = []\n",
    "\n",
    "    for t in random.sample(train_data, len(train_data)):  # sample through all data in random order each epoch\n",
    "        # Get reconstruction loss to help ground abstract state\n",
    "        decoded_values, transition_probabilities = model(t[0])\n",
    "        decode_loss = F.mse_loss(decoded_values[0], t[0], reduction='sum')\n",
    "\n",
    "        # Flatten transition probabilities to then weigh with loss of each predicted state at each layer\n",
    "        first = transition_probabilities[0].view(-1,1,1,1)\n",
    "        second = transition_probabilities[1].view(-1,1,1,1)\n",
    "        third = transition_probabilities[2].view(-1,1,1,1)\n",
    "        fourth = transition_probabilities[3].view(-1,1,1,1)\n",
    "\n",
    "        #Weighted Transitions\n",
    "        # first_loss = (F.mse_loss(decoded_values[1], t[1], reduction='none') * first).sum()\n",
    "        # second_loss = (F.mse_loss(decoded_values[2], t[2], reduction='none') * second).sum()\n",
    "        # third_loss = (F.mse_loss(decoded_values[3], t[3], reduction='none') * third).sum()\n",
    "        # fourth_loss = (F.mse_loss(decoded_values[4], t[4], reduction='none') * fourth).sum()\n",
    "\n",
    "        #Greedy Policy (Squeezing to eliminate batch and channel dimensions)\n",
    "        first_loss = (F.mse_loss(decoded_values[1][first.argmax()].squeeze(0),t[1].squeeze(0).squeeze(0)))\n",
    "        second_loss = (F.mse_loss(decoded_values[2][second.argmax()].squeeze(0),t[2].squeeze(0).squeeze(0)))\n",
    "        third_loss = (F.mse_loss(decoded_values[3][third.argmax()].squeeze(0),t[3].squeeze(0).squeeze(0)))\n",
    "        fourth_loss = (F.mse_loss(decoded_values[4][fourth.argmax()].squeeze(0),t[4].squeeze(0).squeeze(0)))\n",
    "\n",
    "        total_loss = first_loss + second_loss  + third_loss  + fourth_loss + decode_loss\n",
    "\n",
    "        # break if total loss is nan\n",
    "        if torch.isnan(total_loss):\n",
    "            raise ValueError(\"NAN LOSS\")\n",
    "\n",
    "\n",
    "        avg_decode_loss += decode_loss.item()\n",
    "        avg_first_loss += first_loss.item()\n",
    "        avg_second_loss += second_loss.item()\n",
    "        avg_third_loss += third_loss.item()\n",
    "        avg_fourth_loss += fourth_loss.item()\n",
    "        avg_loss += total_loss.item()\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        # Monitor gradients before clipping and stepping\n",
    "        all_gradients.append(image_world.store_gradients(model))\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0: \n",
    "        #print just validation\n",
    "        print(f\"Epoch {epoch + 1}, Validation Loss Weighted: {image_world.validate(model, valid_data,weighted=True)}, | Validation Unweighted Avg: {image_world.validate(model, valid_data,weighted=False)/5}\")\n",
    "\n",
    "    #Individual Lossses\n",
    "    avg_decode_loss = avg_decode_loss / len(train_data)\n",
    "    avg_first_loss = avg_first_loss / len(train_data)\n",
    "    avg_second_loss = avg_second_loss / len(train_data)\n",
    "    avg_third_loss = avg_third_loss / len(train_data)\n",
    "    avg_fourth_loss = avg_fourth_loss / len(train_data)\n",
    "    #Full Loss\n",
    "    avg_train_loss = avg_loss / len(train_data)\n",
    "    \n",
    "    # avg_decode_loss = (avg_decode_loss / len(train_data))/0.0025\n",
    "    # avg_first_loss = (avg_first_loss / len(train_data))/0.0025\n",
    "    # avg_second_loss = (avg_second_loss / len(train_data))/0.0025\n",
    "    # avg_third_loss = (avg_third_loss / len(train_data))/0.0025\n",
    "    # avg_fourth_loss = (avg_fourth_loss / len(train_data))/0.0025\n",
    "    # #Full Loss\n",
    "    # avg_train_loss = (avg_loss / len(train_data))/0.0025    \n",
    "    # if (avg_decode_loss + avg_first_loss + avg_second_loss + avg_third_loss + avg_fourth_loss) < 2:\n",
    "    #     break\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Total Loss: {avg_train_loss}, DLoss: {avg_decode_loss}, A1: {avg_first_loss}, A2: {avg_second_loss}, A3: {avg_third_loss}, A4: {avg_fourth_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "#torch.save(model.state_dict(), 'model.pth')\n",
    "#load model\n",
    "#model.load_state_dict(torch.load('model_1500.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transition_fun: 0.0\n",
      "decoder.fc.weight: 0.06\n",
      "decoder.fc.bias: 0.0\n",
      "decoder.deconv1.weight: 0.22\n",
      "decoder.deconv1.bias: 0.01\n",
      "decoder.deconv2.weight: 0.24\n",
      "decoder.deconv2.bias: 0.05\n",
      "decoder.final_conv.weight: 0.23\n",
      "decoder.final_conv.bias: 0.12\n",
      "encoder.cnn_encoder.conv1.weight: 0.04\n",
      "encoder.cnn_encoder.conv1.bias: 0.14\n",
      "encoder.cnn_encoder.bn1.weight: 0.01\n",
      "encoder.cnn_encoder.bn1.bias: 0.01\n",
      "encoder.cnn_encoder.conv2.weight: 0.09\n",
      "encoder.cnn_encoder.conv2.bias: 0.01\n",
      "encoder.cnn_encoder.bn2.weight: 0.01\n",
      "encoder.cnn_encoder.bn2.bias: 0.0\n",
      "encoder.cnn_encoder.conv3.weight: 0.08\n",
      "encoder.cnn_encoder.conv3.bias: 0.0\n",
      "encoder.cnn_encoder.bn3.weight: 0.0\n",
      "encoder.cnn_encoder.bn3.bias: 0.0\n",
      "encoder.cnn_encoder.residual_conv.weight: 0.01\n",
      "encoder.cnn_encoder.residual_conv.bias: 0.0\n",
      "encoder.linear.weight: 0.13\n",
      "encoder.linear.bias: 0.0\n"
     ]
    }
   ],
   "source": [
    "for name, num in all_gradients[-1]:\n",
    "    print(name +':', round(num, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>View Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Original Start State:\n",
      " tensor([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "Max True Original Start State: (7, 8)\n",
      "Decoded Next States\n",
      "Action: 0\n",
      "Next State:\n",
      " tensor([[ 0., -0., -0.,  0.,  0., -0.,  0., -0.,  0.,  0.,  0., -0.],\n",
      "        [ 0.,  0., -0., -0.,  0., -0.,  0.,  0., -0.,  0., -0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., -0.,  0., -0., -0., -0., -0., -0.],\n",
      "        [-0., -0., -0., -0.,  0.,  0.,  0.,  0., -0.,  0., -0.,  0.],\n",
      "        [ 0.,  0.,  0., -0.,  0.,  0., -0.,  0.,  0.,  0., -0., -0.],\n",
      "        [-0.,  0., -0.,  0.,  0., -0.,  0.,  0., -0.,  0., -0.,  0.],\n",
      "        [-0.,  0.,  0.,  0., -0.,  0., -1., -0., -0., -0.,  0.,  0.],\n",
      "        [ 0., -0.,  0., -0., -0., -0.,  0., -0., -0., -0., -0.,  0.],\n",
      "        [ 0.,  0., -0., -0., -0.,  0., -0., -0., -0., -0.,  0., -0.],\n",
      "        [-0.,  0., -0.,  0.,  0.,  0.,  0., -0., -0., -0., -0., -0.],\n",
      "        [-0., -0., -0., -0.,  0.,  0., -0., -0.,  0., -0., -0., -0.],\n",
      "        [ 0.,  0., -0.,  0., -0.,  0., -0.,  0.,  0.,  0., -0.,  0.]])\n",
      "Max Value Decoded: (8, 8)\n",
      "Action: 1\n",
      "Next State:\n",
      " tensor([[ 0., -0., -0., -0.,  0., -0.,  0., -0.,  0.,  0.,  0., -0.],\n",
      "        [ 0.,  0.,  0., -0.,  0., -0., -0.,  0., -0.,  0., -0.,  0.],\n",
      "        [ 0., -0., -0., -0.,  0., -0.,  0., -0.,  0., -0., -0.,  0.],\n",
      "        [ 0.,  0.,  0., -0.,  0.,  0.,  0.,  0.,  0.,  0., -0.,  0.],\n",
      "        [ 0.,  0.,  0., -0.,  0.,  0., -0.,  0.,  0.,  0., -0., -0.],\n",
      "        [-0.,  0., -0.,  0.,  0., -0., -0.,  0., -0.,  0., -0., -0.],\n",
      "        [ 0., -0.,  0.,  0., -0.,  0., -1.,  0., -0.,  0.,  0.,  0.],\n",
      "        [ 0., -0., -0.,  0.,  0.,  0.,  0., -0., -0., -0., -0.,  0.],\n",
      "        [-0.,  0., -0.,  0., -0., -0., -0., -0.,  0., -0., -0., -0.],\n",
      "        [-0.,  0., -0.,  0., -0.,  0.,  0.,  0., -0., -0.,  0.,  0.],\n",
      "        [-0., -0., -0.,  0.,  0.,  0., -0., -0.,  0., -0.,  0.,  0.],\n",
      "        [-0.,  0., -0.,  0.,  0.,  0.,  0.,  0., -0.,  0., -0., -0.]])\n",
      "Max Value Decoded: (7, 9)\n",
      "Action: 2\n",
      "Next State:\n",
      " tensor([[ 0.,  0.,  0., -0., -0., -0.,  0., -0.,  0.,  0., -0.,  0.],\n",
      "        [ 0., -0., -0., -0.,  0.,  0., -0.,  0., -0.,  0., -0.,  0.],\n",
      "        [ 0.,  0., -0., -0., -0., -0.,  0., -0.,  0., -0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., -0.,  0.,  0.,  0., -0., -0., -0., -0., -0.],\n",
      "        [ 0.,  0., -0., -0.,  0.,  0., -0.,  0.,  0.,  0., -0., -0.],\n",
      "        [ 0., -0., -0.,  0., -0.,  0.,  0.,  0., -0.,  0., -0., -0.],\n",
      "        [-0.,  0.,  0.,  0., -0.,  0., -1., -0., -0.,  0.,  0.,  0.],\n",
      "        [ 0., -0.,  0., -0.,  0.,  0., -0., -0., -0., -0.,  0.,  0.],\n",
      "        [ 0., -0.,  0., -0.,  0., -0., -0., -0.,  0., -0.,  0., -0.],\n",
      "        [ 0., -0., -0.,  0., -0.,  0.,  0., -0., -0.,  0., -0., -0.],\n",
      "        [ 0., -0., -0., -0.,  0.,  0., -0.,  0., -0.,  0., -0., -0.],\n",
      "        [ 0.,  0., -0.,  0.,  0.,  0., -0., -0.,  0.,  0., -0.,  0.]])\n",
      "Max Value Decoded: (8, 8)\n",
      "Action: 3\n",
      "Next State:\n",
      " tensor([[ 0., -0., -0.,  0.,  0., -0.,  0., -0.,  0.,  0.,  0., -0.],\n",
      "        [ 0., -0., -0., -0.,  0., -0.,  0., -0., -0.,  0., -0.,  0.],\n",
      "        [ 0.,  0., -0.,  0.,  0., -0.,  0., -0.,  0., -0.,  0., -0.],\n",
      "        [-0.,  0.,  0., -0.,  0.,  0.,  0.,  0.,  0.,  0., -0., -0.],\n",
      "        [ 0.,  0., -0., -0.,  0.,  0., -0.,  0.,  0.,  0., -0., -0.],\n",
      "        [-0.,  0., -0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -0.,  0.],\n",
      "        [-0.,  0.,  0.,  0., -0.,  0., -1., -0., -0., -0.,  0., -0.],\n",
      "        [ 0., -0.,  0., -0.,  0., -0., -0., -0., -0.,  0., -0.,  0.],\n",
      "        [-0., -0., -0., -0.,  0.,  0., -0., -0.,  0., -0.,  0.,  0.],\n",
      "        [-0.,  0., -0.,  0.,  0.,  0.,  0., -0.,  0.,  0.,  0.,  0.],\n",
      "        [-0., -0.,  0., -0.,  0., -0., -0., -0.,  0.,  0.,  0., -0.],\n",
      "        [-0.,  0., -0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "Max Value Decoded: (8, 8)\n"
     ]
    }
   ],
   "source": [
    "image_world.action_viewer(model,start_state=train_data[0][0],actions = [0,1,2,3],shrink=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Path\n",
      "7 8\n",
      "8 8\n",
      "8 9\n",
      "8 10\n",
      "9 10\n",
      "True Original Start State:\n",
      " tensor([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "Max True Original Start State: (7, 8)\n",
      "Decoded Next States\n",
      "Action: 3\n",
      "Next State:\n",
      " tensor([[ 0., -0., -0.,  0.,  0., -0.,  0., -0.,  0.,  0.,  0., -0.],\n",
      "        [ 0., -0., -0., -0.,  0., -0.,  0., -0., -0.,  0., -0.,  0.],\n",
      "        [ 0.,  0., -0.,  0.,  0., -0.,  0., -0.,  0., -0.,  0., -0.],\n",
      "        [-0.,  0.,  0., -0.,  0.,  0.,  0.,  0.,  0.,  0., -0., -0.],\n",
      "        [ 0.,  0., -0., -0.,  0.,  0., -0.,  0.,  0.,  0., -0., -0.],\n",
      "        [-0.,  0., -0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -0.,  0.],\n",
      "        [-0.,  0.,  0.,  0., -0.,  0., -1., -0., -0., -0.,  0., -0.],\n",
      "        [ 0., -0.,  0., -0.,  0., -0., -0., -0., -0.,  0., -0.,  0.],\n",
      "        [-0., -0., -0., -0.,  0.,  0., -0., -0.,  0., -0.,  0.,  0.],\n",
      "        [-0.,  0., -0.,  0.,  0.,  0.,  0., -0.,  0.,  0.,  0.,  0.],\n",
      "        [-0., -0.,  0., -0.,  0., -0., -0., -0.,  0.,  0.,  0., -0.],\n",
      "        [-0.,  0., -0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "Max Value Decoded: (8, 8)\n",
      "Action: 1\n",
      "Next State:\n",
      " tensor([[ 0., -0., -0., -0.,  0., -0.,  0., -0.,  0.,  0.,  0., -0.],\n",
      "        [ 0.,  0.,  0., -0.,  0., -0., -0.,  0., -0.,  0., -0.,  0.],\n",
      "        [ 0., -0., -0., -0.,  0., -0.,  0., -0.,  0., -0., -0.,  0.],\n",
      "        [ 0.,  0.,  0., -0.,  0.,  0.,  0.,  0.,  0.,  0., -0.,  0.],\n",
      "        [ 0.,  0.,  0., -0.,  0.,  0., -0.,  0.,  0.,  0., -0., -0.],\n",
      "        [-0.,  0., -0.,  0.,  0., -0., -0.,  0., -0.,  0., -0., -0.],\n",
      "        [ 0., -0.,  0.,  0., -0.,  0., -1.,  0., -0.,  0.,  0.,  0.],\n",
      "        [ 0., -0., -0.,  0.,  0.,  0.,  0., -0., -0., -0., -0.,  0.],\n",
      "        [-0.,  0., -0.,  0., -0., -0., -0., -0.,  0., -0., -0., -0.],\n",
      "        [-0.,  0., -0.,  0., -0.,  0.,  0.,  0., -0., -0.,  0.,  0.],\n",
      "        [-0., -0., -0.,  0.,  0.,  0., -0., -0.,  0., -0.,  0.,  0.],\n",
      "        [-0.,  0., -0.,  0.,  0.,  0.,  0.,  0., -0.,  0., -0., -0.]])\n",
      "Max Value Decoded: (7, 9)\n",
      "Action: 3\n",
      "Next State:\n",
      " tensor([[ 0., -0., -0.,  0.,  0., -0.,  0., -0.,  0.,  0.,  0., -0.],\n",
      "        [ 0., -0., -0., -0.,  0., -0.,  0., -0., -0.,  0., -0.,  0.],\n",
      "        [ 0.,  0., -0.,  0.,  0., -0.,  0., -0.,  0., -0.,  0., -0.],\n",
      "        [-0.,  0.,  0., -0.,  0.,  0.,  0.,  0.,  0.,  0., -0., -0.],\n",
      "        [ 0.,  0., -0., -0.,  0.,  0., -0.,  0.,  0.,  0., -0., -0.],\n",
      "        [-0.,  0., -0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -0.,  0.],\n",
      "        [-0.,  0.,  0.,  0., -0.,  0., -1., -0., -0., -0.,  0., -0.],\n",
      "        [ 0., -0.,  0., -0.,  0., -0., -0., -0., -0.,  0., -0.,  0.],\n",
      "        [-0., -0., -0., -0.,  0.,  0., -0., -0.,  0., -0.,  0.,  0.],\n",
      "        [-0.,  0., -0.,  0.,  0.,  0.,  0., -0.,  0.,  0.,  0.,  0.],\n",
      "        [-0., -0.,  0., -0.,  0., -0., -0., -0.,  0.,  0.,  0., -0.],\n",
      "        [-0.,  0., -0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "Max Value Decoded: (8, 8)\n",
      "Action: 3\n",
      "Next State:\n",
      " tensor([[ 0., -0., -0.,  0.,  0., -0.,  0., -0.,  0.,  0.,  0., -0.],\n",
      "        [ 0., -0., -0., -0.,  0., -0.,  0., -0., -0.,  0., -0.,  0.],\n",
      "        [ 0.,  0., -0.,  0.,  0., -0.,  0., -0.,  0., -0.,  0., -0.],\n",
      "        [-0.,  0.,  0., -0.,  0.,  0.,  0.,  0.,  0.,  0., -0., -0.],\n",
      "        [ 0.,  0., -0., -0.,  0.,  0., -0.,  0.,  0.,  0., -0., -0.],\n",
      "        [-0.,  0., -0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -0.,  0.],\n",
      "        [-0.,  0.,  0.,  0., -0.,  0., -1., -0., -0., -0.,  0., -0.],\n",
      "        [ 0., -0.,  0., -0.,  0., -0., -0., -0., -0.,  0., -0.,  0.],\n",
      "        [-0., -0., -0., -0.,  0.,  0., -0., -0.,  0., -0.,  0.,  0.],\n",
      "        [-0.,  0., -0.,  0.,  0.,  0.,  0., -0.,  0.,  0.,  0.,  0.],\n",
      "        [-0., -0.,  0., -0.,  0., -0., -0., -0.,  0.,  0.,  0., -0.],\n",
      "        [-0.,  0., -0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "Max Value Decoded: (8, 8)\n"
     ]
    }
   ],
   "source": [
    "image_world.view_greedy_path(model,start_state=train_data[0],shrink=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Action 1    1.322873\n",
       "Action 2    0.630054\n",
       "Action 3    1.450892\n",
       "Action 4    1.317476\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_df = image_world.get_action_df(model,valid_data)\n",
    "action_df.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Action 1</th>\n",
       "      <th>Action 2</th>\n",
       "      <th>Action 3</th>\n",
       "      <th>Action 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Action 1  Action 2  Action 3  Action 4\n",
       "0         3         1         3         1\n",
       "1         2         3         1         3\n",
       "2         3         2         0         3\n",
       "3         0         1         3         2\n",
       "4         3         3         3         3\n",
       "5         1         2         1         3\n",
       "6         0         2         1         3\n",
       "7         3         1         3         1\n",
       "8         2         3         1         3\n",
       "9         2         3         1         3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220, 16)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_rows = action_df.drop_duplicates()\n",
    "len(action_df), len(unique_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
